{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d4254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the model dimensions to 192\n",
    "## using multiple heads  (2)\n",
    "## also increments upto 100\n",
    "\n",
    "## Train with random sequences generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3d592-49eb-4a56-83b1-1762e1c819f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installations\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install torch\n",
    "#!pip install tqdm\n",
    "#!pip install torchvision\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7abc0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "import inspect\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "#set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"Sequence_task_pytorch\"\n",
    "\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "#inflect package - number2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a73459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13b5730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce33c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size, batch =1):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (batch, 1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e335236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = nnF.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c90686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # Stack all weight matrices 1...h together for efficiency\n",
    "        # Note that in many implementations you see \"bias=False\" which is optional\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        # Original Transformer initialization, see PyTorch documentation\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False, return_v=False):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # Separate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # Determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n",
    "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
    "        o = self.o_proj(values)\n",
    "\n",
    "        if return_attention:\n",
    "            if return_v:\n",
    "                return o,attention,v, self.o_proj.weight, self.o_proj.bias\n",
    "            else:\n",
    "                return o, attention \n",
    "        else:\n",
    "            return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624cf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_dim - Dimensionality of the input\n",
    "            num_heads - Number of heads to use in the attention block\n",
    "            dim_feedforward - Dimensionality of the hidden layer in the MLP\n",
    "            dropout - Dropout probability to use in the dropout layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Attention layer\n",
    "        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n",
    "\n",
    "        # Two-layer MLP\n",
    "        self.linear_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, dim_feedforward),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim_feedforward, input_dim)\n",
    "        )\n",
    "\n",
    "        # Layers to apply in between the main layers\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Attention part\n",
    "        attn_out = self.self_attn(x, mask=mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # MLP part\n",
    "        linear_out = self.linear_net(x)\n",
    "        x = x + self.dropout(linear_out)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60dcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers, **block_args):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for l in self.layers:\n",
    "            x = l(x, mask=mask)\n",
    "        return x\n",
    "\n",
    "    def get_attention_maps(self, x, mask=None):\n",
    "        attention_maps = []\n",
    "        for l in self.layers:\n",
    "            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n",
    "            attention_maps.append(attn_map)\n",
    "            x = l(x, mask=mask)\n",
    "        return attention_maps\n",
    "    \n",
    "    def get_norm_maps(self, x, mask=None):\n",
    "        norm_maps = []\n",
    "        for l in self.layers:\n",
    "            _, attn_map, v,W_o, b_o = l.self_attn(x, mask=mask, return_attention=True, return_v=True)\n",
    "            print(W_o.shape, b_o.shape)\n",
    "            norm_map = torch.linalg.norm( torch.einsum('ijkl,ijlm->ijklm',attn_map,v), axis = -1)\n",
    "            print(norm_map.size)\n",
    "            norm_maps.append(norm_map)\n",
    "            x = l(x, mask=mask)\n",
    "        return norm_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a46dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6037a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25156a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, dropout=0.0, input_dropout=0.0):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_dim - Hidden dimensionality of the input\n",
    "            model_dim - Hidden dimensionality to use inside the Transformer\n",
    "            num_classes - Number of classes to predict per sequence element\n",
    "            num_heads - Number of heads to use in the Multi-Head Attention blocks\n",
    "            num_layers - Number of encoder blocks to use.\n",
    "            dropout - Dropout to apply inside the model\n",
    "            input_dropout - Dropout to apply on the input features\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        for item in inspect.signature(Transformer).parameters:\n",
    "            setattr(self, item, eval(item))\n",
    "        \n",
    "        # Input dim -> Model dim\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Dropout(input_dropout),\n",
    "            nn.Linear(input_dim, model_dim)\n",
    "        )\n",
    "        # Positional encoding for sequences\n",
    "        self.positional_encoding = PositionalEncoding(d_model=model_dim)\n",
    "        # Transformer\n",
    "        self.transformer = TransformerEncoder(num_layers=num_layers,\n",
    "                                              input_dim=model_dim,\n",
    "                                              dim_feedforward=2*model_dim,\n",
    "                                              num_heads=num_heads,\n",
    "                                              dropout=dropout)\n",
    "        # Output classifier per sequence element\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(model_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features of shape [Batch, SeqLen, input_dim]\n",
    "            mask - Mask to apply on the attention outputs (optional)\n",
    "            add_positional_encoding - If True, we add the positional encoding to the input.\n",
    "                                      Might not be desired for some tasks.\n",
    "        \"\"\"\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        x = self.output_net(x)\n",
    "                \n",
    "        return x\n",
    "\n",
    "    def get_attention_maps(self, x, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"\n",
    "        Function for extracting the attention matrices of the whole Transformer for a single batch.\n",
    "        Input arguments same as the forward pass.\n",
    "        \"\"\"\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n",
    "        return attention_maps\n",
    "    \n",
    "    def get_norm_maps(self, x, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"\n",
    "        Function for extracting the norm matrices of the whole Transformer for a single batch.\n",
    "        Input arguments same as the forward pass.\n",
    "        \"\"\"\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        norm_maps = self.transformer.get_norm_maps(x, mask=mask)\n",
    "        return norm_maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21156f92",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c38ac3-7c58-43eb-bc43-bdf937849ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 11\n"
     ]
    }
   ],
   "source": [
    "class SmallDataset(data.Dataset):\n",
    "    def __init__(self, num_categories, seq_len, size = 20):\n",
    "        #super().__init()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        #array = np.arange(self.seq_len)\n",
    "            \n",
    "        #self.data = torch.from_numpy(array)\n",
    "        \n",
    "        #array = np.array([np.sort(np.random.choice(np.arange(1,100), 10, replace=False, p= (1/99)*np.ones(99) )) for i in np.arange(size)])\n",
    "        \n",
    "        outer_array = np.empty(size)\n",
    "        \n",
    "        \n",
    "        for i in range (size):\n",
    "            start = np.random.randint(0, 500)\n",
    "            \n",
    "            inner_array = np.empty(self.seq_len)\n",
    "            \n",
    "            for j in range (self.seq_len):\n",
    "                inner_array[j] = start\n",
    "                \n",
    "                start += 1\n",
    "                \n",
    "            outer_array[i] = inner_array\n",
    "        \n",
    "                \n",
    "                \n",
    "        \n",
    "        array = np.array([np.sort(np.random.choice(np.arange(1,100), 10, replace=False, p= (1/99)*np.ones(99) )) for i in np.arange(size)])\n",
    "        \n",
    "        print(array.shape)\n",
    "        #print(array)\n",
    "        \n",
    "        #print(outer_array.shape)\n",
    "        \n",
    "        self.data = torch.from_numpy(array)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.size()[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp_data = self.data[idx]\n",
    "        \n",
    "        \n",
    "        # predict the next number (adding 1)\n",
    "        change = inp_data - np.roll(inp_data,1 )\n",
    "        \n",
    "        print(\"Change: \", change) \n",
    "        change[0] = 0 \n",
    "        labels = inp_data + change\n",
    "        \n",
    "        return inp_data, labels\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66d816-785a-4d86-afda-eeb7f65f2c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test?\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "n_cat = 3\n",
    "print(\"Test?\")\n",
    "full_dataset = SmallDataset(n_cat, seq_len)\n",
    "print(\"dataset generated\")\n",
    "print(len(full_dataset))\n",
    "print(full_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20323d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sequenceDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, num_categories, seq_len, size= 1000000):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        #self.size = size\n",
    "        \n",
    "        self.data = torch.from_numpy(np.array([np.sort(np.random.choice(np.arange(1,10000), 10, replace=False, p= (1/9999)*np.ones(9999) )) for i in np.arange(size)]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size()[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp_data = self.data[idx]\n",
    "                        \n",
    "        # predict the next number (adding 1)\n",
    "        change = inp_data - np.roll(inp_data,1 )\n",
    "        change[0] = 0 \n",
    "        labels = inp_data + change\n",
    "        \n",
    "        return inp_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cfac6ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m n_cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m \u001b[43msequenceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_cat\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(full_dataset))\n\u001b[1;32m      8\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_dataset))\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36msequenceDataset.__init__\u001b[0;34m(self, num_categories, seq_len, size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m=\u001b[39m seq_len\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#self.size = size\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39msort(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10000\u001b[39m), \u001b[38;5;241m10\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, p\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m9999\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m9999\u001b[39m) )) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(size)]))\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m=\u001b[39m seq_len\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#self.size = size\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39msort(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m9999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(size)]))\n",
      "File \u001b[0;32mmtrand.pyx:981\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Jupyter_work/environment/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2569\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumsum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2497\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;124;03m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2567\u001b[0m \n\u001b[1;32m   2568\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Jupyter_work/environment/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "n_cat = 10000\n",
    "full_dataset = sequenceDataset(n_cat , seq_len)\n",
    "print(len(full_dataset))\n",
    "\n",
    "\n",
    "'''\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.1 * len(full_dataset))\n",
    "test_size = len(full_dataset)-train_size -val_size\n",
    "batch = 512\n",
    "print(train_size, val_size, test_size)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size,val_size, test_size])\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_loader   = data.DataLoader(val_dataset, batch_size=batch)\n",
    "test_loader  = data.DataLoader(test_dataset, batch_size=batch)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea3652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: tensor([1868, 2658, 3481, 3701, 3863, 6139, 6368, 6730, 7186, 8949])\n",
      "Labels:     tensor([ 1868,  3448,  4304,  3921,  4025,  8415,  6597,  7092,  7642, 10712])\n",
      "tensor([   0,  790,  823,  220,  162, 2276,  229,  362,  456, 1763])\n"
     ]
    }
   ],
   "source": [
    "## Sample input--output\n",
    "\n",
    "inp_data, labels = train_loader.dataset[0]\n",
    "print(\"Input data:\", inp_data)\n",
    "print(\"Labels:    \", labels)\n",
    "print(torch.abs(labels-inp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c7eb363",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1627336334951/work/aten/src/THC/THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-787bac76848c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1627336334951/work/aten/src/THC/THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "## Distribution of change in Training data\n",
    "\n",
    "ch = np.zeros(int(train_size/batch)*batch*seq_len)\n",
    "\n",
    "for i,(data, labels) in enumerate(train_loader):\n",
    "    ch[i*seq_len*batch :(i+1)*seq_len*batch ] = np.abs(labels.view(-1)- data.view(-1))\n",
    "\n",
    "plt.hist(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909bce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of change in Validation data\n",
    "\n",
    "ch = np.zeros(val_size*seq_len)\n",
    "\n",
    "for i,(data, labels) in enumerate(val_loader):\n",
    "    ch[i*seq_len*batch :(i+1)*seq_len*batch  ] = np.abs(labels.view(-1)- data.view(-1))\n",
    "\n",
    "plt.hist(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of change in Validation data\n",
    "\n",
    "ch = np.zeros(test_size*seq_len)\n",
    "\n",
    "for i,(data, labels) in enumerate(test_loader):\n",
    "    ch[i*seq_len*batch :(i+1)*seq_len*batch  ] = np.abs(labels.view(-1)- data.view(-1))\n",
    "\n",
    "plt.hist(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3609ad",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e31017",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model params\n",
    "\n",
    "input_dim=full_dataset.num_categories*2\n",
    "model_dim= 192    ### increased from 32\n",
    "num_heads= 2        ##increased from 1\n",
    "num_classes=full_dataset.num_categories*2\n",
    "num_layers=1      \n",
    "dropout=0.0\n",
    "lr=5e-4\n",
    "warmup=50\n",
    "max_epochs = 200\n",
    "max_iters= max_epochs*len(train_loader)\n",
    "\n",
    "## Training with validation\n",
    "model = Transformer(input_dim, model_dim, num_classes, num_heads, num_layers,dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "## Initializing optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# Apply lr scheduler per step\n",
    "lr_scheduler = CosineWarmupScheduler(optimizer,\n",
    "                                     warmup=warmup,\n",
    "                                     max_iters=max_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training with validation \n",
    "\n",
    "def calculate_loss(data, labels, model):\n",
    "    seq_len = labels.size()[1]\n",
    "    data = nnF.one_hot(data, num_classes= num_classes).float()\n",
    "    target= model.forward(data, mask = subsequent_mask(data.size(-2),data.size(0)).to(device),add_positional_encoding=True)\n",
    "\n",
    "    target_ = target.view(-1,target.size(-1))\n",
    "    labels_ = labels.view(-1)\n",
    "    \n",
    "    loss = nnF.cross_entropy(target_, labels_ ) \n",
    "    \n",
    "    return loss, target\n",
    "\n",
    "def training(model, train_loader, val_loader,epochs,num_classes):\n",
    "    \n",
    "    # start with pretrained weights\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'saved_model_upd_dataset.pth')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        checkpoint = torch.load(pretrained_filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Early stopping\n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "    min_val_loss = np.inf\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = 0.0\n",
    "        model.train()     \n",
    "        for i,(data, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "            loss,_ = calculate_loss(data, labels, model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()    \n",
    "        for data, labels in val_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "            loss,_ = calculate_loss(data, labels, model)\n",
    "            # Calculate Loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / len(train_loader)} \\t\\t Validation Loss: {val_loss / len(val_loader)}')\n",
    "        \n",
    "        \n",
    "        if min_val_loss > val_loss:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "            print(f'Validation Loss Decreased({min_val_loss:.6f}--->{val_loss:.6f}) \\t Saving The Model')\n",
    "            min_val_loss = val_loss\n",
    "            # Saving State Dict\n",
    "            os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "            pretrained_filename = os.path.join(CHECKPOINT_PATH,'saved_model_upd_dataset_final.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                }, pretrained_filename)  \n",
    "        '''   \n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\n')\n",
    "                return model\n",
    "        ''' \n",
    "            \n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9bbe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether pretrained model exists. If yes, load it and skip training\n",
    "pretrained_filename = os.path.join(CHECKPOINT_PATH, 'saved_model_upd_dataset_final.pth')\n",
    "if os.path.isfile(pretrained_filename):\n",
    "    print(\"Found pretrained model, loading...\")\n",
    "    checkpoint = torch.load(pretrained_filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "else:\n",
    "    model = training(model, train_loader, val_loader,max_epochs,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i,(data, labels) in tqdm(enumerate(test_loader)):\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = data.to(device), labels.to(device)        \n",
    "            loss, target = calculate_loss(data, labels, model)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            acc = (target.argmax(dim=-1) == labels).float().mean()\n",
    "            test_acc += acc\n",
    "\n",
    "        print(\"Loss:\", test_loss / len(test_loader),\"\\n\",\"Accuracy:\", 100*(test_acc.item() / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ba897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train-set: \")\n",
    "test(model, train_loader)\n",
    "print(\"Val-set: \")\n",
    "test(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d275bd",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef932555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test-set: \")\n",
    "test(model, test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f78701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_test, labels_test = next(iter(test_loader))\n",
    "inp_data_test = nnF.one_hot(data_input_test[:,:], num_classes=num_classes).float()\n",
    "inp_data_test = inp_data_test.to(device)\n",
    "\n",
    "pred_output =model.forward(inp_data_test,  mask = subsequent_mask(inp_data_test.size(-2),inp_data_test.size(0)).to(device))\n",
    "_, output_test = torch.max(pred_output, dim =-1)\n",
    "print(output_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ac9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(10,20)\n",
    "print(data_input_test[index,:])\n",
    "print(output_test[index,:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442b0a",
   "metadata": {},
   "source": [
    "## Creating attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_maps(input_data, attn_maps, idx=0):\n",
    "    if input_data is not None:\n",
    "        input_data = input_data[idx].detach().cpu().numpy()\n",
    "    else:\n",
    "        input_data =self.log('train_loss', loss) \n",
    "    attn_maps = [m[idx].detach().cpu().numpy() for m in attn_maps]\n",
    "\n",
    "    num_heads = attn_maps[0].shape[0]\n",
    "    num_layers = len(attn_maps)\n",
    "    seq_len = input_data.shape[0]\n",
    "    fig_size = 4 if num_heads == 1 else 3\n",
    "    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n",
    "    if num_layers == 1:\n",
    "        ax = [ax]\n",
    "    if num_heads == 1:\n",
    "        ax = [[a] for a in ax]\n",
    "    \n",
    "    for row in range(num_layers):\n",
    "        for column in range(num_heads):\n",
    "            #print(attn_maps[row][column])\n",
    "            ax[row][column].imshow(attn_maps[row][column], origin='upper', vmin=0)\n",
    "            ax[row][column].set_xticks(list(range(seq_len)))\n",
    "            ax[row][column].set_xticklabels(input_data.tolist())\n",
    "            ax[row][column].set_yticks(list(range(seq_len)))\n",
    "            ax[row][column].set_yticklabels(input_data.tolist())\n",
    "            ax[row][column].set_title(f\"Layer {row+1}, Head {column+1}\")\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax[row][column].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input, labels = next(iter(val_loader))\n",
    "inp_data = nnF.one_hot(data_input, num_classes=num_classes).float()\n",
    "inp_data = inp_data.to(device)\n",
    "attention_maps = model.get_attention_maps(inp_data,mask = subsequent_mask(inp_data.size(-2),inp_data.size(0)).to(device))\n",
    "norm_maps = model.get_norm_maps(inp_data,mask = subsequent_mask(inp_data.size(-2),inp_data.size(0)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_maps[0].shape)\n",
    "print(norm_maps[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_maps(data_input, attention_maps, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b89b6",
   "metadata": {},
   "source": [
    "## Random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c83e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_input_test = torch.tensor([[1, 3000, 5, 7]])\n",
    "#data_input_test = torch.randint(0, 9999,(13,)).unsqueeze(0)\n",
    "#data_input_test = torch.from_numpy(np.arange(1,15)).unsqueeze(0)\n",
    "\n",
    "#data_input_test = torch.from_numpy(np.arange(4018,3090 ,-101)).unsqueeze(0)\n",
    "data_input_test = torch.from_numpy(np.arange(1,1100, 110)).unsqueeze(0)\n",
    "print(data_input_test)\n",
    "inp_data_test = nnF.one_hot(data_input_test[:,:], num_classes=num_classes).float()\n",
    "inp_data_test = inp_data_test.to(device)\n",
    "\n",
    "pred_output =model.forward(inp_data_test,  mask = subsequent_mask(inp_data_test.size(-2),inp_data_test.size(0)).to(device))\n",
    "_, output_test = torch.max(pred_output, dim =-1)\n",
    "\n",
    "\n",
    "print(output_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_maps_test = model.get_attention_maps(inp_data_test,mask = subsequent_mask(inp_data_test.size(-2),inp_data_test.size(0)).to(device))\n",
    "plot_attention_maps(data_input_test, attention_maps_test, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "class taskDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, num_categories, seq_len):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "\n",
    "        self.data = torch.from_numpy(np.array([np.arange(sv, sv+(self.seq_len*step), step) for step in np.arange(1,1000) for sv in np.arange(1,self.num_categories-(self.seq_len),1) if sv+(self.seq_len*step)< self.num_categories]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size()[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp_data = self.data[idx]\n",
    "\n",
    "        \n",
    "        # predict the next number (adding 1)\n",
    "        change = inp_data - np.roll(inp_data,1 )\n",
    "        change[0] = 0 \n",
    "        labels = inp_data + change\n",
    "        \n",
    "        return inp_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa08bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_test_dataset = taskDataset(10000, 10)\n",
    "print(len(task_test_dataset))\n",
    "\n",
    "task_test_loader  = data.DataLoader(task_test_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample input--output\n",
    "\n",
    "inp_data, labels = task_test_loader.dataset[2222]\n",
    "print(\"Input data:\", inp_data)\n",
    "print(\"Labels:    \", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac390b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Task Test-set: \")\n",
    "test(model, task_test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample random test output\n",
    "\n",
    "data_input_test, labels_test = next(iter(task_test_loader))\n",
    "inp_data_test = nnF.one_hot(data_input_test[:,:], num_classes=num_classes).float()\n",
    "inp_data_test = inp_data_test.to(device)\n",
    "\n",
    "pred_output =model.forward(inp_data_test,  mask = subsequent_mask(inp_data_test.size(-2),inp_data_test.size(0)).to(device))\n",
    "_, output_test = torch.max(pred_output, dim =-1)\n",
    "\n",
    "\n",
    "index = np.arange(200, 210)\n",
    "print(data_input_test[index,:])\n",
    "print(output_test[index,:] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error Analysis\n",
    "\n",
    "model.eval()\n",
    "total_error_rows = 0\n",
    "change =[]\n",
    "with torch.no_grad():\n",
    "    for i,(data, labels) in tqdm(enumerate(task_test_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.to(device), labels.to(device)   \n",
    "        loss, target = calculate_loss(data, labels, model)\n",
    "        acc = (target.argmax(dim=-1) == labels)\n",
    "        total_error_rows += np.unique(np.where(acc.cpu()==0)[0]).shape[0]\n",
    "        change.append(np.array((data[np.unique(np.where(acc.cpu()==0)[0])][:,1] -data[np.unique(np.where(acc.cpu()==0)[0])][:,0]).cpu()))\n",
    "        \n",
    "change = np.concatenate(change, axis=0 )\n",
    "print(change.shape)\n",
    "print(total_error_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a79ad",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4de69",
   "metadata": {},
   "source": [
    "## Checking the layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(inp, model, layers= [4]):\n",
    "    \n",
    "    inp_layers = nn.ModuleList(list(model.input_net)). eval()\n",
    "    pe_layer = model.positional_encoding\n",
    "    trf_layers = nn.ModuleList(list(model.transformer.layers)). eval()\n",
    "    out_layers= nn.ModuleList(list(model.output_net)). eval()\n",
    "    \n",
    "    send_outs ={}\n",
    "\n",
    "    for i, layer in enumerate(inp_layers ):\n",
    "        inp = layer(inp)\n",
    "    \n",
    "    inp = pe_layer(inp)\n",
    "    \n",
    "    for i, layer in enumerate(trf_layers ):\n",
    "        inp =layer(inp, mask = subsequent_mask(inp.size(-2),inp.size(0)).to(device))\n",
    "        \n",
    "    \n",
    "    for i, layer in enumerate(out_layers):\n",
    "        inp = layer(inp)\n",
    "        if i in layers:\n",
    "            out = inp.cpu().detach().numpy()\n",
    "            send_outs[i] = out.squeeze()\n",
    "\n",
    "    return send_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(inp, model, layers= [1]):\n",
    "    \n",
    "    inp_layers = nn.ModuleList(list(model.input_net)). eval()\n",
    "    pe_layer = model.positional_encoding\n",
    "    trf_layers = nn.ModuleList(list(model.transformer.layers)). eval()\n",
    "    out_layers= nn.ModuleList(list(model.output_net)). eval()\n",
    "    \n",
    "    send_outs ={}\n",
    "\n",
    "    for i, layer in enumerate(inp_layers ):\n",
    "        inp = layer(inp)\n",
    "    \n",
    "    out = inp.cpu().detach().numpy()\n",
    "    send_outs[i] = out.squeeze()\n",
    "    \n",
    "    return send_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7b23e",
   "metadata": {},
   "source": [
    "## Input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "data_input = torch.from_numpy(np.arange(1,10000)).unsqueeze(0)\n",
    "inp_data = nnF.one_hot(data_input, num_classes=num_classes).float()\n",
    "inp_data = inp_data.to(device)\n",
    "print(data_input)\n",
    "\n",
    "outs = get_embeddings(inp_data, model)\n",
    "print(outs[1].shape)\n",
    "max_index = 10000-1\n",
    "\n",
    "if os.path.isfile(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz')):\n",
    "    dist_matrix = np.load(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz'))['dist_matrix']   \n",
    "else:\n",
    "    dist_matrix = np.zeros((max_index,max_index))\n",
    "    for i in tqdm(np.arange(max_index)):\n",
    "        for j in np.arange(i,max_index):\n",
    "            dist_matrix[i,j] = spatial.distance.cosine(outs[1][i,:], outs[1][j,:])\n",
    "    np.savez(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz'), dist_matrix= dist_matrix)\n",
    "        \n",
    "#plt.imshow(dist_matrix)\n",
    "#print(dist_matrix)\n",
    "dist_matrix_new = dist_matrix + dist_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "M, N = dist_matrix_new.shape\n",
    "F = fftpack.fftn(dist_matrix_new)\n",
    "F_magnitude = np.abs(F)\n",
    "F_magnitude = fftpack.fftshift(F_magnitude)\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(4.8*2, 4.8*2))\n",
    "im = ax0.imshow(np.log10(1 + F_magnitude), cmap='viridis',extent=(-N // 2, N // 2, -M // 2, M // 2))\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "f.colorbar(im, cax=cax, orientation='vertical')\n",
    "ax0.set_title('Spectrum magnitude');\n",
    "\n",
    "\n",
    "im =ax1.imshow(dist_matrix_new, extent=(1,9999,9999,1))\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "f.colorbar(im, cax=cax, orientation='vertical')\n",
    "ax1.set_title('Cosine distance between Embeddings');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "max_index = 10000-1\n",
    "if os.path.isfile(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz')):\n",
    "    dist_matrix = np.load(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz'))['dist_matrix']   \n",
    "else:\n",
    "    dist_matrix = np.zeros((max_index,max_index))\n",
    "    for i in tqdm(np.arange(max_index)):\n",
    "        for j in np.arange(i,max_index):\n",
    "            dist_matrix[i,j] = spatial.distance.cosine(outs[1][i,:], outs[1][j,:])\n",
    "    np.savez(os.path.join(CHECKPOINT_PATH, 'dist_matrix_updated_dataset.npz'), dist_matrix= dist_matrix)\n",
    "        \n",
    "#plt.imshow(dist_matrix)\n",
    "#print(dist_matrix)\n",
    "dist_matrix_new = dist_matrix + dist_matrix.T\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "nx, ny = dist_matrix_new.shape\n",
    "x ,y = np.arange(1,nx+1), np.arange(1,ny+1)\n",
    "X, Y = np.meshgrid(x, y)  # `plot_surface` expects `x` and `y` data to be 2D\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, dist_matrix_new, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "# Customize the z axis.\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "## distances on number line\n",
    "\n",
    "from scipy import spatial\n",
    "from  functools import reduce\n",
    "\n",
    "\n",
    "if os.path.isfile(os.path.join(CHECKPOINT_PATH, 'dist_matrix_numbers.npz')):\n",
    "    dist_matrix_numbers = np.load(os.path.join(CHECKPOINT_PATH, 'dist_matrix_numbers.npz'))['dist_matrix_number']   \n",
    "else:\n",
    "    size = max_index\n",
    "    vals = np.arange(size)\n",
    "    res = reduce(lambda a, b: a+np.eye(size,k=b[0])*b[1], enumerate(vals), np.zeros((size, size)))\n",
    "    np.savez(os.path.join(CHECKPOINT_PATH, 'dist_matrix_numbers.npz'), dist_matrix_number= res)\n",
    "        \n",
    "#print(dist_matrix)\n",
    "dist_matrix_num = (dist_matrix_numbers + dist_matrix_numbers.T)/max_index \n",
    "#plt.imshow(dist_matrix_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "M, N = dist_matrix_num.shape\n",
    "F = fftpack.fftn(dist_matrix_num)\n",
    "F_magnitude = np.abs(F)\n",
    "F_magnitude = fftpack.fftshift(F_magnitude)\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(4.8*2, 4.8*2))\n",
    "im = ax0.imshow(np.log10(1 + F_magnitude), cmap='viridis',extent=(-N // 2, N // 2, -M // 2, M // 2))\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "f.colorbar(im, cax=cax, orientation='vertical')\n",
    "ax0.set_title('Spectrum magnitude');\n",
    "\n",
    "\n",
    "im =ax1.imshow(dist_matrix_num, extent=(1,9999,9999,1))\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "f.colorbar(im, cax=cax, orientation='vertical')\n",
    "ax1.set_title('Distance Matrix for numbers');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561ca80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd76d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db82809fb2cade75697261d7b202c623291a5920ce0faabfae951ffb2a884568"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
