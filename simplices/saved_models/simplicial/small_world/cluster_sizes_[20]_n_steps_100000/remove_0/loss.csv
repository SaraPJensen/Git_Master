epoch,train_loss,val_loss
1,2534.4950696291244,362.2969868469238
2,490.70392984798974,416.5062806256612
3,497.41886529786245,375.6692804177602
4,475.02239812510356,365.1459190940857
5,464.9230054296766,425.52049509684247
6,464.4899333041055,534.5174541536967
7,482.0038823890686,357.4320306269328
8,467.75039393356866,420.1177984110514
9,457.54633576648575,486.77127415974934
10,437.6239349828448,367.9204431915283
11,431.30637395995007,351.41690088907876
12,427.2550813456944,329.5718583170573
13,416.98958290031976,406.0050593757629
14,394.83817055974686,382.7867467498779
15,399.9657557467052,359.43328769683836
16,400.5668639382294,328.8095020294189
17,390.5066094943455,341.7094255320231
18,384.78231778757913,311.945090268453
19,381.1072674386842,331.18054913838705
20,367.8264426939828,293.18299327850343
21,380.0122954075677,352.64674405415855
22,346.10843215942384,362.97221956888836
23,352.08064834186007,280.12252928733824
24,339.0859580823353,280.6072369003296
25,333.36750528063095,283.77265548706055
26,322.3556635461535,254.26940441131592
27,286.5343313332966,306.44246866861977
28,276.44368493216376,261.24849511464436
29,262.6974647971562,285.29529660542806
30,239.18955577577864,231.87546730041504
31,237.7308054310935,240.20058314005533
32,241.04364180769238,265.6546802902222
33,236.64768826382502,217.9699790986379
34,230.36185599327086,225.1979206530253
35,224.11421660593578,221.54904678344727
36,213.9455043397631,260.6249961280823
37,206.74978526183537,226.74963360468547
38,209.57705087048666,278.52994815190635
39,203.52123389891216,222.22351621627809
40,212.42816770076752,297.61511224746704
41,206.07816460950033,237.99291471481322
42,212.69100282907485,233.11975004673005
43,201.23889927932194,236.27577821095784
44,192.05505519458225,220.37813919067383
45,201.22382621867317,273.7872238922119
46,204.0972776733126,313.2739271291097
47,197.16062165669032,302.051908493042
48,203.38663853645323,301.00297292073566
49,187.0512176656723,216.94174776713052
50,191.45841002600534,226.827477906545
